{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries ðŸ“š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_11424\\4144608217.py:29: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  cmap = mpl.cm.get_cmap('coolwarm')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"  # \"jax\" or \"tensorflow\" or \"torch\"\n",
    "\n",
    "import keras_cv\n",
    "import keras\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "import librosa\n",
    "import IPython.display as ipd\n",
    "import librosa.display as lid\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Set interactive backend\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "cmap = mpl.cm.get_cmap('coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration ðŸ’¥ðŸ’¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = 'content/birdclef-2024'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View the species name and construct a dictionary to hold their values ðŸ“ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = sorted(os.listdir(f\"{DATASET_PATH}/train_audio/\"))\n",
    "num_classes = len(class_names)\n",
    "class_labels = list(range(num_classes))\n",
    "label2name = dict(zip(class_labels, class_names))\n",
    "name2label = {v:k for k,v in label2name.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 182\n",
      "{0: 'asbfly', 1: 'ashdro1', 2: 'ashpri1', 3: 'ashwoo2', 4: 'asikoe2'}\n",
      "{'asbfly': 0, 'ashdro1': 1, 'ashpri1': 2, 'ashwoo2': 3, 'asikoe2': 4}\n"
     ]
    }
   ],
   "source": [
    "## Print out the first 5 items in the label2name and name2label dictionaries\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "print({k: label2name[k] for k in list(label2name)[:5]})\n",
    "print({k: name2label[k] for k in list(name2label)[:5]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataframe ðŸ”ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>primary_label</th>\n",
       "      <th>secondary_labels</th>\n",
       "      <th>type</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>scientific_name</th>\n",
       "      <th>common_name</th>\n",
       "      <th>author</th>\n",
       "      <th>license</th>\n",
       "      <th>rating</th>\n",
       "      <th>url</th>\n",
       "      <th>filename</th>\n",
       "      <th>filepath</th>\n",
       "      <th>target</th>\n",
       "      <th>xc_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23106</th>\n",
       "      <td>whiter2</td>\n",
       "      <td>[]</td>\n",
       "      <td>['']</td>\n",
       "      <td>40.6828</td>\n",
       "      <td>0.8371</td>\n",
       "      <td>Chlidonias hybrida</td>\n",
       "      <td>Whiskered Tern</td>\n",
       "      <td>Pere Josa</td>\n",
       "      <td>Creative Commons Attribution-NonCommercial-Sha...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>https://xeno-canto.org/761899</td>\n",
       "      <td>XC761899.ogg</td>\n",
       "      <td>content/birdclef-2024/train_audio/whiter2/XC76...</td>\n",
       "      <td>174</td>\n",
       "      <td>XC761899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16822</th>\n",
       "      <td>lirplo</td>\n",
       "      <td>[]</td>\n",
       "      <td>['']</td>\n",
       "      <td>40.0710</td>\n",
       "      <td>-4.2880</td>\n",
       "      <td>Charadrius dubius</td>\n",
       "      <td>Little Ringed Plover</td>\n",
       "      <td>Javier GarcÃ­a SÃ¡ez</td>\n",
       "      <td>Creative Commons Attribution-NonCommercial-Sha...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>https://xeno-canto.org/735108</td>\n",
       "      <td>XC735108.ogg</td>\n",
       "      <td>content/birdclef-2024/train_audio/lirplo/XC735...</td>\n",
       "      <td>105</td>\n",
       "      <td>XC735108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12879</th>\n",
       "      <td>grtdro1</td>\n",
       "      <td>['asikoe2']</td>\n",
       "      <td>['song']</td>\n",
       "      <td>13.8549</td>\n",
       "      <td>100.4735</td>\n",
       "      <td>Dicrurus paradiseus</td>\n",
       "      <td>Greater Racket-tailed Drongo</td>\n",
       "      <td>Werzik</td>\n",
       "      <td>Creative Commons Attribution-NonCommercial-Sha...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>https://www.xeno-canto.org/396411</td>\n",
       "      <td>XC396411.ogg</td>\n",
       "      <td>content/birdclef-2024/train_audio/grtdro1/XC39...</td>\n",
       "      <td>73</td>\n",
       "      <td>XC396411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21712</th>\n",
       "      <td>spoowl1</td>\n",
       "      <td>[]</td>\n",
       "      <td>['call']</td>\n",
       "      <td>12.9912</td>\n",
       "      <td>80.2363</td>\n",
       "      <td>Athene brama</td>\n",
       "      <td>Spotted Owlet</td>\n",
       "      <td>Vivek Puliyeri</td>\n",
       "      <td>Creative Commons Attribution-NonCommercial-Sha...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>https://www.xeno-canto.org/276818</td>\n",
       "      <td>XC276818.ogg</td>\n",
       "      <td>content/birdclef-2024/train_audio/spoowl1/XC27...</td>\n",
       "      <td>156</td>\n",
       "      <td>XC276818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>asikoe2</td>\n",
       "      <td>[]</td>\n",
       "      <td>['call', 'female', 'male']</td>\n",
       "      <td>8.7055</td>\n",
       "      <td>81.1875</td>\n",
       "      <td>Eudynamys scolopaceus</td>\n",
       "      <td>Asian Koel</td>\n",
       "      <td>Hugo Wieleman</td>\n",
       "      <td>Creative Commons Attribution-NonCommercial-Sha...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>https://www.xeno-canto.org/330496</td>\n",
       "      <td>XC330496.ogg</td>\n",
       "      <td>content/birdclef-2024/train_audio/asikoe2/XC33...</td>\n",
       "      <td>4</td>\n",
       "      <td>XC330496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      primary_label secondary_labels                        type  latitude  \\\n",
       "23106       whiter2               []                        ['']   40.6828   \n",
       "16822        lirplo               []                        ['']   40.0710   \n",
       "12879       grtdro1      ['asikoe2']                    ['song']   13.8549   \n",
       "21712       spoowl1               []                    ['call']   12.9912   \n",
       "414         asikoe2               []  ['call', 'female', 'male']    8.7055   \n",
       "\n",
       "       longitude        scientific_name                   common_name  \\\n",
       "23106     0.8371     Chlidonias hybrida                Whiskered Tern   \n",
       "16822    -4.2880      Charadrius dubius          Little Ringed Plover   \n",
       "12879   100.4735    Dicrurus paradiseus  Greater Racket-tailed Drongo   \n",
       "21712    80.2363           Athene brama                 Spotted Owlet   \n",
       "414      81.1875  Eudynamys scolopaceus                    Asian Koel   \n",
       "\n",
       "                   author                                            license  \\\n",
       "23106           Pere Josa  Creative Commons Attribution-NonCommercial-Sha...   \n",
       "16822  Javier GarcÃ­a SÃ¡ez  Creative Commons Attribution-NonCommercial-Sha...   \n",
       "12879              Werzik  Creative Commons Attribution-NonCommercial-Sha...   \n",
       "21712      Vivek Puliyeri  Creative Commons Attribution-NonCommercial-Sha...   \n",
       "414         Hugo Wieleman  Creative Commons Attribution-NonCommercial-Sha...   \n",
       "\n",
       "       rating                                url      filename  \\\n",
       "23106     5.0      https://xeno-canto.org/761899  XC761899.ogg   \n",
       "16822     5.0      https://xeno-canto.org/735108  XC735108.ogg   \n",
       "12879     3.5  https://www.xeno-canto.org/396411  XC396411.ogg   \n",
       "21712     4.0  https://www.xeno-canto.org/276818  XC276818.ogg   \n",
       "414       3.0  https://www.xeno-canto.org/330496  XC330496.ogg   \n",
       "\n",
       "                                                filepath  target     xc_id  \n",
       "23106  content/birdclef-2024/train_audio/whiter2/XC76...     174  XC761899  \n",
       "16822  content/birdclef-2024/train_audio/lirplo/XC735...     105  XC735108  \n",
       "12879  content/birdclef-2024/train_audio/grtdro1/XC39...      73  XC396411  \n",
       "21712  content/birdclef-2024/train_audio/spoowl1/XC27...     156  XC276818  \n",
       "414    content/birdclef-2024/train_audio/asikoe2/XC33...       4  XC330496  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f'{DATASET_PATH}/train_metadata.csv')\n",
    "df['filepath'] = DATASET_PATH + '/train_audio/' + df.filename\n",
    "df['target'] = df.primary_label.map(name2label)\n",
    "df['filename'] = df.filepath.map(lambda x: x.split('/')[-1])\n",
    "df['xc_id'] = df.filepath.map(lambda x: x.split('/')[-1].split('.')[0])\n",
    "\n",
    "## display a few rows\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to retreive an audio file ðŸŽµ\n",
    "**librosa is a python package for music and audio analysis. It provides the building blocks necessary to create music information retrieval systems**\n",
    "[Documentation here](https://librosa.org/doc/latest/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the audio as a waveform `y`\n",
    "# Store the sampling rate as `sr`\n",
    "def load_audio(filepath):\n",
    "    audio, sr = librosa.load(filepath)\n",
    "    return audio, sr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the audio spectrogram ðŸŒŠ. \n",
    "**A spectrogram is a visual representation of the spectrum of frequencies of a signal as it varies with time. When applied to an audio signal, spectrograms are sometimes called sonographs, voiceprints, or voicegrams**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sampling rate of the audio signal (32 kHz)\n",
    "sample_rate = 32000\n",
    "\n",
    "# Define the maximum frequency to include in the spectrogram (16 kHz)\n",
    "fmax = 16000\n",
    "\n",
    "# Define the minimum frequency to include in the spectrogram (20 Hz)\n",
    "fmin = 20\n",
    "\n",
    "# Function to compute the Mel-spectrogram of an audio signal\n",
    "def get_spectrogram(audio):\n",
    "    # Compute the Mel-spectrogram\n",
    "    spec = librosa.feature.melspectrogram(\n",
    "        y=audio,  # Input audio signal\n",
    "        sr=sample_rate,  # Sampling rate of the audio\n",
    "        n_mels=256,  # Number of Mel bands (frequency bins)\n",
    "        n_fft=2048,  # Size of the FFT window (determines frequency resolution)\n",
    "        hop_length=512,  # Number of samples between successive frames (determines time resolution)\n",
    "        fmax=fmax,  # Maximum frequency to include in the spectrogram\n",
    "        fmin=fmin,  # Minimum frequency to include in the spectrogram\n",
    "    )\n",
    "\n",
    "    # Convert the power spectrogram to decibel (dB) scale\n",
    "    # This makes the values more perceptually meaningful\n",
    "    spec = librosa.power_to_db(spec, ref=1.0)  # ref=1.0 is the reference value for dB calculation\n",
    "\n",
    "    # Normalize the spectrogram to the range [0, 1]\n",
    "    min_ = spec.min()  # Minimum value in the spectrogram\n",
    "    max_ = spec.max()  # Maximum value in the spectrogram\n",
    "    if max_ != min_:  # Avoid division by zero if the spectrogram is constant\n",
    "        spec = (spec - min_) / (max_ - min_)  # Normalize using min-max scaling\n",
    "\n",
    "    # Return the normalized Mel-spectrogram\n",
    "    return spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display a few audio files with spectograms and their associated df details âš¡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration = 15\n",
    "audio_len = duration * sample_rate\n",
    "def display_audio(row):\n",
    "    caption = f'Id: {row.filename} | Name: {row.common_name} | Sci.Name: {row.scientific_name}'\n",
    "    \n",
    "    audio, sr = load_audio(row.filepath)\n",
    "    audio = audio[:audio_len]\n",
    "    spec = get_spectrogram(audio)\n",
    "    \n",
    "    # Audio output widget\n",
    "    audio_output = widgets.Output()\n",
    "    with audio_output:\n",
    "        display(ipd.Audio(audio, rate=sample_rate))\n",
    "    \n",
    "    # Plot output widget\n",
    "    plot_output = widgets.Output()\n",
    "    with plot_output:\n",
    "        fig, ax = plt.subplots(2, 1, figsize=(12, 6), sharex=True, tight_layout=True)\n",
    "        fig.suptitle(caption)\n",
    "        \n",
    "        # Plot waveform\n",
    "        lid.waveshow(audio, sr=sample_rate, ax=ax[0], color='b')\n",
    "        \n",
    "        # Plot spectrogram\n",
    "        lid.specshow(spec, sr=sample_rate, hop_length=512, n_fft=2048,\n",
    "                     fmin=fmin, fmax=fmax, x_axis='time', y_axis='mel', \n",
    "                     cmap='coolwarm', ax=ax[1])\n",
    "        \n",
    "        ax[0].set_xlabel('')\n",
    "        plt.show()\n",
    "\n",
    "    # Display side-by-side\n",
    "    display(widgets.HBox([audio_output, plot_output]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82b8872012d94336bd7d003f8b750f76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0055540ce58c4553a93ee20f42cfa961",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "decf6d5a641e4651acb7a283a140311d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Display a few audio samples\n",
    "for i in range(3):\n",
    "    display_audio(df.sample(1).iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a decoder parse files into spectrogramsðŸš€ \n",
    "\n",
    "**The build_decoder() function constructs a decoder that can process audio files into spectrograms.\n",
    "It loads, normalizes, and converts the audio into a Mel-spectrogram.\n",
    "If with_labels=True, it also converts labels into one-hot vectors.\n",
    "The output is an RGB-like spectrogram image that can be used as input to CNNs.**\n",
    "[Tensorflow Documentation here](https://www.tensorflow.org/io/api_docs/python/tfio/audio/spectrogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image and audio parameters\n",
    "img_size = [128, 384]  # Spectrogram image size (height, width)\n",
    "batch_size = 64  # Batch size for training\n",
    "hop_length = audio_len // (img_size[1] - 1)  # Hop length for spectrogram computation\n",
    "nfft = 2028  # FFT window size for computing the spectrogram\n",
    "\n",
    "def build_decoder(with_labels=True, dim=1024):\n",
    "    \"\"\"\n",
    "    Builds a function to decode and preprocess audio files into spectrograms.\n",
    "    \n",
    "    Parameters:\n",
    "    - with_labels (bool): Whether to return labels along with spectrograms.\n",
    "    - dim (int): Target audio length (number of samples).\n",
    "    \n",
    "    Returns:\n",
    "    - Function to decode audio files (with or without labels).\n",
    "    \"\"\"\n",
    "\n",
    "    def get_audio(filepath):\n",
    "        \"\"\"Loads and decodes an audio file from a given filepath.\"\"\"\n",
    "        file_bytes = tf.io.read_file(filepath)  # Read the audio file as bytes\n",
    "        audio = tfio.audio.decode_vorbis(file_bytes)  # Decode .ogg Vorbis file\n",
    "        audio = tf.cast(audio, tf.float32)  # Convert to float32\n",
    "\n",
    "        # Convert stereo to mono by selecting only one channel\n",
    "        if tf.shape(audio)[1] > 1:\n",
    "            audio = audio[..., 0:1]\n",
    "        audio = tf.squeeze(audio, axis=-1)  # Remove redundant dimensions\n",
    "        return audio\n",
    "\n",
    "    def crop_or_pad(audio, target_len, pad_mode=\"constant\"):\n",
    "        \"\"\"Ensures the audio is of fixed length by either cropping or padding.\"\"\"\n",
    "        audio_len = tf.shape(audio)[0]  # Get current length of audio\n",
    "        diff_len = abs(target_len - audio_len)  # Difference from target length\n",
    "\n",
    "        if audio_len < target_len:\n",
    "            # If audio is shorter, pad it randomly on both sides\n",
    "            pad1 = tf.random.uniform([], maxval=diff_len, dtype=tf.int32)\n",
    "            pad2 = diff_len - pad1\n",
    "            audio = tf.pad(audio, paddings=[[pad1, pad2]], mode=pad_mode)\n",
    "\n",
    "        elif audio_len > target_len:\n",
    "            # If audio is longer, randomly crop a section\n",
    "            idx = tf.random.uniform([], maxval=diff_len, dtype=tf.int32)\n",
    "            audio = audio[idx : (idx + target_len)]\n",
    "\n",
    "        return tf.reshape(audio, [target_len])  # Ensure fixed shape\n",
    "\n",
    "    def apply_preproc(spec):\n",
    "        \"\"\"Applies standardization and normalization to the spectrogram.\"\"\"\n",
    "        # Standardization: Zero mean and unit variance\n",
    "        mean = tf.math.reduce_mean(spec)\n",
    "        std = tf.math.reduce_std(spec)\n",
    "        spec = tf.where(tf.math.equal(std, 0), spec - mean, (spec - mean) / std)\n",
    "\n",
    "        # Min-Max Normalization: Scale values between 0 and 1\n",
    "        min_val = tf.math.reduce_min(spec)\n",
    "        max_val = tf.math.reduce_max(spec)\n",
    "        spec = tf.where(\n",
    "            tf.math.equal(max_val - min_val, 0), \n",
    "            spec - min_val, \n",
    "            (spec - min_val) / (max_val - min_val)\n",
    "        )\n",
    "\n",
    "        return spec\n",
    "\n",
    "    def get_target(target):\n",
    "        \"\"\"Converts a label into a one-hot encoded vector.\"\"\"\n",
    "        target = tf.reshape(target, [1])  # Reshape to single element tensor\n",
    "        target = tf.cast(tf.one_hot(target, num_classes), tf.float32)  # One-hot encoding\n",
    "        return tf.reshape(target, [num_classes])  # Reshape to match the output format\n",
    "\n",
    "    def decode(path):\n",
    "        \"\"\"Processes an audio file into a spectrogram image.\"\"\"\n",
    "        # Load and preprocess the audio\n",
    "        audio = get_audio(path)\n",
    "        audio = crop_or_pad(audio, dim)  # Ensure fixed length\n",
    "        \n",
    "        # Convert audio to a Mel-spectrogram\n",
    "        spec = keras.layers.MelSpectrogram(\n",
    "            num_mel_bins=img_size[0],  # Number of Mel frequency bins (height of image)\n",
    "            fft_length=nfft,  # FFT window size\n",
    "            sequence_stride=hop_length,  # Step size between spectrogram columns\n",
    "            sampling_rate=sample_rate,  # Sample rate of audio\n",
    "        )(audio)\n",
    "\n",
    "        spec = apply_preproc(spec)  # Apply normalization and standardization\n",
    "        \n",
    "        # Convert spectrogram into a 3-channel image (for compatibility with CNNs)\n",
    "        spec = tf.tile(spec[..., None], [1, 1, 3])  # Repeat values along the last axis\n",
    "        return tf.reshape(spec, [*img_size, 3])  # Reshape to (height, width, 3)\n",
    "\n",
    "    def decode_with_labels(path, label):\n",
    "        \"\"\"Processes an audio file into a spectrogram and returns it with its label.\"\"\"\n",
    "        return decode(path), get_target(label)\n",
    "\n",
    "    return decode_with_labels if with_labels else decode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
