{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m9/m7xl4h0s4dxcq7r_gtrcb8m80000gn/T/ipykernel_50730/2327640484.py:22: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  cmap = mpl.cm.get_cmap('coolwarm')\n"
     ]
    }
   ],
   "source": [
    "## Importing Libraries\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"  # \"jax\" or \"tensorflow\" or \"torch\" \n",
    "\n",
    "import keras_cv\n",
    "import keras\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "import librosa\n",
    "import IPython.display as ipd\n",
    "import librosa.display as lid\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "cmap = mpl.cm.get_cmap('coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8444\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>content/birdclef-2024/unlabeled_soundscapes/18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>content/birdclef-2024/unlabeled_soundscapes/26...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>content/birdclef-2024/unlabeled_soundscapes/66...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>content/birdclef-2024/unlabeled_soundscapes/12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>content/birdclef-2024/unlabeled_soundscapes/16...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filepath\n",
       "0  content/birdclef-2024/unlabeled_soundscapes/18...\n",
       "1  content/birdclef-2024/unlabeled_soundscapes/26...\n",
       "2  content/birdclef-2024/unlabeled_soundscapes/66...\n",
       "3  content/birdclef-2024/unlabeled_soundscapes/12...\n",
       "4  content/birdclef-2024/unlabeled_soundscapes/16..."
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Set the test data path\n",
    "DATASET_PATH = 'content/birdclef-2024'\n",
    "#`unlabeled_soundscapes` is the set of data downloaded together with the training data.\n",
    "#`test_soundscapes` will be populated on the site when submission of the results from `unlabbed_soundscapes` is done.\n",
    "test_paths = glob(f'{DATASET_PATH}/test_soundscapes/*ogg')\n",
    "if len(test_paths)==0:\n",
    "    # current_paths = glob(f'{DATASET_PATH}/unlabeled_soundscapes/*ogg')\n",
    "    test_paths = glob(f'{DATASET_PATH}/unlabeled_soundscapes/*ogg')\n",
    "    print(len(test_paths))\n",
    "test_df = pd.DataFrame(test_paths, columns=['filepath'])\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "## To handle our settings  and configurations, let's create a class\n",
    "class Config:\n",
    "    seed = 42\n",
    "    # Input image size and batch size\n",
    "    img_size = [128, 384]\n",
    "    \n",
    "    # Audio duration, sample rate, and length\n",
    "    duration = 15 # second\n",
    "    sample_rate = 32000\n",
    "    audio_len = duration*sample_rate\n",
    "    \n",
    "    # STFT parameters\n",
    "    nfft = 2028\n",
    "    window = 2048\n",
    "    hop_length = audio_len // (img_size[1] - 1)\n",
    "    fmin = 20\n",
    "    fmax = 16000\n",
    "    \n",
    "    #model name\n",
    "    preset = 'efficientnetv2_b2_imagenet'\n",
    "    class_names = sorted(os.listdir(f'{DATASET_PATH}/train_audio/'))\n",
    "    num_classes = len(class_names)\n",
    "    class_labels = list(range(num_classes))\n",
    "    label2name = dict(zip(class_labels, class_names))\n",
    "    name2label = {v:k for k,v in label2name.items()} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8444, 1)\n"
     ]
    }
   ],
   "source": [
    "# print(Config.class_names)\n",
    "# for file in Config.class_names:\n",
    "#     print(file)\n",
    "\n",
    "tf.keras.utils.set_random_seed(Config.seed)\n",
    "print(test_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Load the model\n",
    "\n",
    "# Create an input layer for the model\n",
    "inp = keras.layers.Input(shape=(Config.img_size[0], Config.img_size[1], 3))\n",
    "# Pretrained backbone\n",
    "backbone = keras_cv.models.EfficientNetV2Backbone.from_preset(\n",
    "    Config.preset,\n",
    ")\n",
    "out = keras_cv.models.ImageClassifier(\n",
    "    backbone=backbone,\n",
    "    num_classes=Config.num_classes,\n",
    "    name=\"classifier\"\n",
    ")(inp)\n",
    "# Build model\n",
    "model = keras.models.Model(inputs=inp, outputs=out)\n",
    "# Load weights of trained model\n",
    "model.load_weights(\"best_model.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_decoder(with_labels=True, dim=1024):\n",
    "    def get_audio(filepath):\n",
    "        def _load_audio(filepath):\n",
    "            audio, _ = librosa.load(filepath.numpy().decode('utf-8'), sr=Config.sample_rate, mono=True)\n",
    "            # Pad or truncate the audio to a fixed length\n",
    "            if len(audio) < Config.audio_len:\n",
    "                audio = np.pad(audio, (0, Config.audio_len - len(audio)), mode='constant')\n",
    "            else:\n",
    "                audio = audio[:Config.audio_len]\n",
    "            return audio.astype(np.float32)\n",
    "\n",
    "        audio = tf.py_function(_load_audio, [filepath], tf.float32)\n",
    "        audio.set_shape([Config.audio_len])  # Ensure fixed shape\n",
    "        return audio\n",
    "\n",
    "    def create_frames(audio, duration=5, sr=32000):\n",
    "        frame_size = int(duration * sr)\n",
    "        # Pad the audio to ensure it can be divided evenly into frames\n",
    "        padding_size = (frame_size - (len(audio) % frame_size)) % frame_size\n",
    "        audio = tf.pad(audio, [[0, padding_size]])\n",
    "        frames = tf.reshape(audio, [-1, frame_size])\n",
    "        return frames\n",
    "\n",
    "    def apply_preproc(spec):\n",
    "        mean = tf.math.reduce_mean(spec)\n",
    "        std = tf.math.reduce_std(spec)\n",
    "        spec = tf.where(tf.math.equal(std, 0), spec - mean, (spec - mean) / std)\n",
    "        min_val = tf.math.reduce_min(spec)\n",
    "        max_val = tf.math.reduce_max(spec)\n",
    "        spec = tf.where(tf.math.equal(max_val - min_val, 0), spec - min_val, (spec - min_val) / (max_val - min_val))\n",
    "        return spec\n",
    "\n",
    "    def decode(path):\n",
    "        audio = get_audio(path)\n",
    "        print(f\"Audio shape: {audio.shape}\")\n",
    "        \n",
    "        audio = create_frames(audio)\n",
    "        print(f\"Frames shape: {audio.shape}\")\n",
    "        \n",
    "        # Compute the spectrogram\n",
    "        spec = keras.layers.MelSpectrogram(\n",
    "            num_mel_bins=Config.img_size[0],\n",
    "            fft_length=Config.nfft,\n",
    "            sequence_stride=Config.hop_length,\n",
    "            sampling_rate=Config.sample_rate\n",
    "        )(audio)\n",
    "        print(f\"Spectrogram shape before adding channel: {spec.shape}\")\n",
    "        \n",
    "        # Add a channel dimension\n",
    "        spec = tf.expand_dims(spec, axis=-1)  # Shape: [batch_size, height, width, 1]\n",
    "        print(f\"Spectrogram shape after adding channel: {spec.shape}\")\n",
    "        \n",
    "        # Transpose the spectrogram to (batch_size, width, height, channels)\n",
    "        spec = tf.transpose(spec, perm=[0, 2, 1, 3])  # Swap height and width\n",
    "        print(f\"Spectrogram shape after transpose: {spec.shape}\")\n",
    "        \n",
    "        # Resize the spectrogram to the expected width (384)\n",
    "        if spec.shape[2] != Config.img_size[1]:\n",
    "            spec = tf.image.resize(spec, [Config.img_size[0], Config.img_size[1]])\n",
    "        print(f\"Spectrogram shape after resize: {spec.shape}\")\n",
    "        \n",
    "        # Apply preprocessing\n",
    "        spec = apply_preproc(spec)\n",
    "        \n",
    "        # Convert to 3-channel image\n",
    "        spec = tf.tile(spec, [1, 1, 1, 3])\n",
    "        print(f\"Final spec shape: {spec.shape}\")\n",
    "        \n",
    "        return spec\n",
    "    return decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build data loader\n",
    "def build_dataset(paths, batch_size=1, decode_fn=None, cache=False):\n",
    "    if decode_fn is None:\n",
    "        decode_fn = build_decoder(dim=Config.audio_len) # decoder\n",
    "    AUTO = tf.data.experimental.AUTOTUNE\n",
    "    slices = (paths,)\n",
    "    ds = tf.data.Dataset.from_tensor_slices(slices)\n",
    "    ds = ds.map(decode_fn, num_parallel_calls=AUTO) # decode audio to spectrograms then create frames\n",
    "    ds = ds.cache() if cache else ds # cache files\n",
    "    ds = ds.batch(batch_size, drop_remainder=False) # create batches\n",
    "    ds = ds.prefetch(AUTO)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kaggleSubmission():\n",
    "        # Initialize empty list to store ids\n",
    "    ids = []\n",
    "\n",
    "    # Initialize empty array to store predictions\n",
    "    preds = np.empty(shape=(0, Config.num_classes), dtype='float32')\n",
    "\n",
    "    # Build test dataset\n",
    "    test_paths = test_df.filepath.tolist()\n",
    "    test_ds = build_dataset(paths=test_paths, batch_size=1)\n",
    "\n",
    "    # Iterate over each audio file in the test dataset\n",
    "    for idx, specs in enumerate(tqdm(iter(test_ds), desc='test ', total=len(test_df))):\n",
    "        # Extract the filename without the extension\n",
    "        filename = test_paths[idx].split('/')[-1].replace('.ogg','')\n",
    "        \n",
    "        # Convert to backend-specific tensor while excluding extra dimension\n",
    "        specs = keras.ops.convert_to_tensor(specs[0])\n",
    "        \n",
    "        # Predict bird species for all frames in a recording using all trained models\n",
    "        frame_preds = model.predict(specs, verbose=0)\n",
    "        \n",
    "        # Create a ID for each frame in a recording using the filename and frame number\n",
    "        frame_ids = [f'{filename}_{(frame_id+1)*5}' for frame_id in range(len(frame_preds))]\n",
    "        \n",
    "        # Concatenate the ids\n",
    "        ids += frame_ids\n",
    "        # Concatenate the predictions\n",
    "        preds = np.concatenate([preds, frame_preds], axis=0)\n",
    "\n",
    "\n",
    "        # Submit prediction\n",
    "    pred_df = pd.DataFrame(ids, columns=['row_id'])\n",
    "    pred_df.loc[:, Config.class_names] = preds\n",
    "    pred_df.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def simple_prediction():\n",
    "    # Initialize lists to store file names and predicted classes\n",
    "    file_names = []\n",
    "    predicted_classes = []\n",
    "\n",
    "    # Build test dataset\n",
    "    test_paths = test_df.filepath.tolist()\n",
    "    test_ds = build_dataset(paths=test_paths, batch_size=1)\n",
    "\n",
    "    # Iterate over each audio file in the test dataset\n",
    "    for idx, specs in enumerate(tqdm(iter(test_ds), desc='Predicting', total=len(test_df))):\n",
    "        # Extract the filename\n",
    "        filename = test_paths[idx].split('/')[-1]\n",
    "        \n",
    "        # Convert to backend-specific tensor while excluding extra dimension\n",
    "        specs = keras.ops.convert_to_tensor(specs[0])\n",
    "        \n",
    "        # Predict bird species for all frames in a recording\n",
    "        frame_preds = model.predict(specs, verbose=0)\n",
    "        \n",
    "        # Get the predicted class for each frame (average predictions across frames)\n",
    "        avg_preds = np.mean(frame_preds, axis=0)\n",
    "        predicted_class_idx = np.argmax(avg_preds)\n",
    "        predicted_class = Config.label2name[predicted_class_idx]\n",
    "        \n",
    "        # Append results to lists\n",
    "        file_names.append(filename)\n",
    "        predicted_classes.append(predicted_class)\n",
    "\n",
    "    # Create a DataFrame with the results\n",
    "    results_df = pd.DataFrame({\n",
    "        'File': file_names,\n",
    "        'Predicted Class': predicted_classes\n",
    "    })\n",
    "\n",
    "    # Save the results to a CSV file\n",
    "    results_df.to_csv('predictions.csv', index=False)\n",
    "    print(\"Predictions saved to 'predictions.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio shape: (480000,)\n",
      "Frames shape: (3, 160000)\n",
      "Spectrogram shape before adding channel: (3, 128, 128)\n",
      "Spectrogram shape after adding channel: (3, 128, 128, 1)\n",
      "Spectrogram shape after transpose: (3, 128, 128, 1)\n",
      "Spectrogram shape after resize: (3, 128, 384, 1)\n",
      "Final spec shape: (3, 128, 384, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test : 100%|██████████| 8444/8444 [11:39<00:00, 12.07it/s]\n"
     ]
    }
   ],
   "source": [
    "# simple_prediction()\n",
    "kaggleSubmission()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
